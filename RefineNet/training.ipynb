{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Unzipped to: /teamspace/studios/this_studio/unzipped\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "zip_path = \"/teamspace/studios/this_studio/hand_segmentation_splitted-20251112T075029Z-1-001.zip\"\n",
    "extract_dir = \"/teamspace/studios/this_studio/unzipped\"  # or any folder you want\n",
    "\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)\n",
    "\n",
    "print(\"âœ… Unzipped to:\", extract_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import shutil\n",
    "from glob import glob\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Configuration ---\n",
      "Device: cuda\n",
      "Dataset Base: /teamspace/studios/this_studio/unzipped/hand_segmentation_splitted\n",
      "Weights: /teamspace/studios/this_studio/weights_hands_epoch_38.pth.tar\n",
      "Checkpoints: /teamspace/studios/this_studio/models_checkpoints\n",
      "Batch Size: 4\n",
      "Epochs: 15\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "HAND_SPLIT_BASE = \"/teamspace/studios/this_studio/unzipped/hand_segmentation_splitted\"\n",
    "PRETRAINED_WEIGHTS = \"/teamspace/studios/this_studio/weights_hands_epoch_38.pth.tar\"\n",
    "OUTPUT_DIR = \"/teamspace/studios/this_studio/models_checkpoints\"\n",
    "\n",
    "assert Path(HAND_SPLIT_BASE).exists(), f\"Dataset not found: {HAND_SPLIT_BASE}\"\n",
    "assert Path(PRETRAINED_WEIGHTS).exists(), f\"Weights not found: {PRETRAINED_WEIGHTS}\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "BASE_DATASETS = ['egohands', 'ego_youtube_hands', 'gtea', 'hand_over_face']\n",
    "DATASETS = BASE_DATASETS + ['combined4']\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 15\n",
    "LR = 1e-4\n",
    "NUM_CLASSES = 2\n",
    "IMG_SIZE = (512, 512)\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "IMG_MEAN = np.array([0.485, 0.456, 0.406]).reshape((1, 1, 3))\n",
    "IMG_STD = np.array([0.229, 0.224, 0.225]).reshape((1, 1, 3))\n",
    "\n",
    "print(f\"--- Configuration ---\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Dataset Base: {HAND_SPLIT_BASE}\")\n",
    "print(f\"Weights: {PRETRAINED_WEIGHTS}\")\n",
    "print(f\"Checkpoints: {OUTPUT_DIR}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"---------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exists: True size (MB): 1351.9839839935303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded type: <class 'dict'>\n",
      "Keys: ['epoch', 'model_state_dict', 'optimizer_state_dict', 'loss']\n",
      "Saved epoch: 38\n",
      "Saved loss: 0.06732065253596328\n"
     ]
    }
   ],
   "source": [
    "# Cell: inspect checkpoint keys & basic info\n",
    "import os, torch\n",
    "p = PRETRAINED_WEIGHTS\n",
    "print(\"exists:\", os.path.exists(p), \"size (MB):\", os.path.getsize(p)/(1024*1024))\n",
    "ck = torch.load(p, map_location=\"cpu\")\n",
    "print(\"Loaded type:\", type(ck))\n",
    "if isinstance(ck, dict):\n",
    "    print(\"Keys:\", list(ck.keys()))\n",
    "    print(\"Saved epoch:\", ck.get('epoch'))\n",
    "    print(\"Saved loss:\", ck.get('loss'))\n",
    "else:\n",
    "    print(\"Not a dict â€” likely a raw state_dict.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchnorm(in_planes):\n",
    "    return nn.BatchNorm2d(in_planes, affine=True, eps=1e-5, momentum=0.1)\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, bias=False):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=bias)\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1, bias=False):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n",
    "                     padding=0, bias=bias)\n",
    "\n",
    "def convbnrelu(in_planes, out_planes, kernel_size, stride=1, groups=1, act=True):\n",
    "    if act:\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_planes, out_planes, kernel_size, stride=stride,\n",
    "                      padding=int(kernel_size / 2.), groups=groups, bias=False),\n",
    "            batchnorm(out_planes),\n",
    "            nn.ReLU6(inplace=True))\n",
    "    else:\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_planes, out_planes, kernel_size, stride=stride,\n",
    "                      padding=int(kernel_size / 2.), groups=groups, bias=False),\n",
    "            batchnorm(out_planes))\n",
    "\n",
    "class CRPBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, n_stages):\n",
    "        super(CRPBlock, self).__init__()\n",
    "        for i in range(n_stages):\n",
    "            setattr(self, '{}_{}'.format(i + 1, 'outvar_dimred'),\n",
    "                    conv3x3(in_planes if (i == 0) else out_planes,\n",
    "                            out_planes, stride=1, bias=False))\n",
    "        self.n_stages = n_stages\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=5, stride=1, padding=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        top = x\n",
    "        for i in range(self.n_stages):\n",
    "            top = self.maxpool(top)\n",
    "            top = getattr(self, '{}_{}'.format(i + 1, 'outvar_dimred'))(top)\n",
    "            x = top + x\n",
    "        return x\n",
    "\n",
    "stages_suffixes = {0 : '_conv', 1 : '_conv_relu_varout_dimred'}\n",
    "\n",
    "class RCUBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, n_blocks, n_stages):\n",
    "        super(RCUBlock, self).__init__()\n",
    "        for i in range(n_blocks):\n",
    "            for j in range(n_stages):\n",
    "                setattr(self, '{}{}'.format(i + 1, stages_suffixes[j]),\n",
    "                        conv3x3(in_planes if (i == 0) and (j == 0) else out_planes,\n",
    "                                out_planes, stride=1, bias=(j == 0)))\n",
    "        self.n_blocks = n_blocks\n",
    "        self.n_stages = n_stages\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(self.n_blocks):\n",
    "            residual = x\n",
    "            for j in range(self.n_stages):\n",
    "                x = F.relu(x)\n",
    "                x = getattr(self, '{}{}'.format(i + 1, stages_suffixes[j]))(x)\n",
    "            x += residual\n",
    "        return x\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x); out = self.bn1(out); out = self.relu(out)\n",
    "        out = self.conv2(out); out = self.bn2(out)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual; out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x); out = self.bn1(out); out = self.relu(out)\n",
    "        out = self.conv2(out); out = self.bn2(out); out = self.relu(out)\n",
    "        out = self.conv3(out); out = self.bn3(out)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual; out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class RefineNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=21):\n",
    "        self.inplanes = 64\n",
    "        super(RefineNet, self).__init__()\n",
    "        self.do = nn.Dropout(p=0.5)\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "\n",
    "        self.p_ims1d2_outl1_dimred = conv3x3(2048, 512, bias=False)\n",
    "        self.adapt_stage1_b = self._make_rcu(512, 512, 2, 2)\n",
    "        self.mflow_conv_g1_pool = self._make_crp(512, 512, 4)\n",
    "        self.mflow_conv_g1_b = self._make_rcu(512, 512, 3, 2)\n",
    "        self.mflow_conv_g1_b3_joint_varout_dimred = conv3x3(512, 256, bias=False)\n",
    "\n",
    "        self.p_ims1d2_outl2_dimred = conv3x3(1024, 256, bias=False)\n",
    "        self.adapt_stage2_b = self._make_rcu(256, 256, 2, 2)\n",
    "        self.adapt_stage2_b2_joint_varout_dimred = conv3x3(256, 256, bias=False)\n",
    "        self.mflow_conv_g2_pool = self._make_crp(256, 256, 4)\n",
    "        self.mflow_conv_g2_b = self._make_rcu(256, 256, 3, 2)\n",
    "        self.mflow_conv_g2_b3_joint_varout_dimred = conv3x3(256, 256, bias=False)\n",
    "\n",
    "        self.p_ims1d2_outl3_dimred = conv3x3(512, 256, bias=False)\n",
    "        self.adapt_stage3_b = self._make_rcu(256, 256, 2, 2)\n",
    "        self.adapt_stage3_b2_joint_varout_dimred = conv3x3(256, 256, bias=False)\n",
    "        self.mflow_conv_g3_pool = self._make_crp(256, 256, 4)\n",
    "        self.mflow_conv_g3_b = self._make_rcu(256, 256, 3, 2)\n",
    "        self.mflow_conv_g3_b3_joint_varout_dimred = conv3x3(256, 256, bias=False)\n",
    "\n",
    "        self.p_ims1d2_outl4_dimred = conv3x3(256, 256, bias=False)\n",
    "        self.adapt_stage4_b = self._make_rcu(256, 256, 2, 2)\n",
    "        self.adapt_stage4_b2_joint_varout_dimred = conv3x3(256, 256, bias=False)\n",
    "        self.mflow_conv_g4_pool = self._make_crp(256, 256, 4)\n",
    "        self.mflow_conv_g4_b = self._make_rcu(256, 256, 3, 2)\n",
    "\n",
    "        self.clf_conv = nn.Conv2d(256, num_classes, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "\n",
    "    def _make_crp(self, in_planes, out_planes, stages):\n",
    "        layers = [CRPBlock(in_planes, out_planes, stages)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_rcu(self, in_planes, out_planes, blocks, stages):\n",
    "        layers = [RCUBlock(in_planes, out_planes, blocks, stages)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        inp_size = x.size()[2:]\n",
    "        x = self.conv1(x); x = self.bn1(x); x = self.relu(x); x = self.maxpool(x)\n",
    "        l1 = self.layer1(x); l2 = self.layer2(l1); l3 = self.layer3(l2); l4 = self.layer4(l3)\n",
    "\n",
    "        l4 = self.do(l4); l3 = self.do(l3)\n",
    "\n",
    "        x4 = self.p_ims1d2_outl1_dimred(l4)\n",
    "        x4 = self.adapt_stage1_b(x4); x4 = self.relu(x4)\n",
    "        x4 = self.mflow_conv_g1_pool(x4); x4 = self.mflow_conv_g1_b(x4)\n",
    "        x4 = self.mflow_conv_g1_b3_joint_varout_dimred(x4)\n",
    "        x4 = nn.Upsample(size=l3.size()[2:], mode='bilinear', align_corners=True)(x4)\n",
    "\n",
    "        x3 = self.p_ims1d2_outl2_dimred(l3)\n",
    "        x3 = self.adapt_stage2_b(x3); x3 = self.adapt_stage2_b2_joint_varout_dimred(x3)\n",
    "        x3 = x3 + x4; x3 = F.relu(x3)\n",
    "        x3 = self.mflow_conv_g2_pool(x3); x3 = self.mflow_conv_g2_b(x3)\n",
    "        x3 = self.mflow_conv_g2_b3_joint_varout_dimred(x3)\n",
    "        x3 = nn.Upsample(size=l2.size()[2:], mode='bilinear', align_corners=True)(x3)\n",
    "\n",
    "        x2 = self.p_ims1d2_outl3_dimred(l2)\n",
    "        x2 = self.adapt_stage3_b(x2); x2 = self.adapt_stage3_b2_joint_varout_dimred(x2)\n",
    "        x2 = x2 + x3; x2 = F.relu(x2)\n",
    "        x2 = self.mflow_conv_g3_pool(x2); x2 = self.mflow_conv_g3_b(x2)\n",
    "        x2 = self.mflow_conv_g3_b3_joint_varout_dimred(x2)\n",
    "        x2 = nn.Upsample(size=l1.size()[2:], mode='bilinear', align_corners=True)(x2)\n",
    "\n",
    "        x1 = self.p_ims1d2_outl4_dimred(l1)\n",
    "        x1 = self.adapt_stage4_b(x1); x1 = self.adapt_stage4_b2_joint_varout_dimred(x1)\n",
    "        x1 = x1 + x2; x1 = F.relu(x1)\n",
    "        x1 = self.mflow_conv_g4_pool(x1); x1 = self.mflow_conv_g4_b(x1)\n",
    "        x1 = self.do(x1)\n",
    "\n",
    "        out = self.clf_conv(x1)\n",
    "        out = F.interpolate(out, size=inp_size, mode='bilinear', align_corners=True)\n",
    "        return out\n",
    "\n",
    "def rf101(num_classes=21, imagenet=False, pretrained=False, **kwargs):\n",
    "    model = RefineNet(Bottleneck, [3, 4, 23, 3], num_classes=num_classes, **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandSegmentationDataset(Dataset):\n",
    "    def __init__(self, img_root, mask_root, split='train'):\n",
    "        self.img_dir = os.path.join(img_root, split)\n",
    "        self.mask_dir = os.path.join(mask_root, split)\n",
    "        self.files = [f for f in os.listdir(self.img_dir) if f.lower().endswith(('jpg', 'png', 'jpeg'))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.files[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, self.files[idx].rsplit('.',1)[0] + '.jpg')\n",
    "        image = np.array(Image.open(img_path).convert('RGB').resize(IMG_SIZE, Image.BILINEAR)).astype(np.float32)/255.\n",
    "        mask = np.array(Image.open(mask_path).convert('L').resize(IMG_SIZE, Image.NEAREST))\n",
    "        mask = (mask>0).astype(np.int64)\n",
    "        norm = (image - IMG_MEAN)/IMG_STD\n",
    "        img_tensor = torch.tensor(norm.transpose(2,0,1)).float()\n",
    "        mask_tensor = torch.tensor(mask).long()\n",
    "        return {'image': img_tensor, 'mask': mask_tensor}\n",
    "\n",
    "def build_split_dataset(name, split):\n",
    "    if name != 'combined4':\n",
    "        img_dir  = os.path.join(HAND_SPLIT_BASE, name, 'images_splitted')\n",
    "        mask_dir = os.path.join(HAND_SPLIT_BASE, name, 'masks_splitted')\n",
    "        return HandSegmentationDataset(img_dir, mask_dir, split)\n",
    "    else:\n",
    "        parts = []\n",
    "        for d in BASE_DATASETS:\n",
    "            img_dir  = os.path.join(HAND_SPLIT_BASE, d, 'images_splitted')\n",
    "            mask_dir = os.path.join(HAND_SPLIT_BASE, d, 'masks_splitted')\n",
    "            parts.append(HandSegmentationDataset(img_dir, mask_dir, split))\n",
    "        return ConcatDataset(parts)\n",
    "\n",
    "def collate_skip_none(batch):\n",
    "    batch = [b for b in batch if b is not None]\n",
    "    if not batch:\n",
    "        return None\n",
    "    return torch.utils.data.dataloader.default_collate(batch)\n",
    "\n",
    "def intersection_and_union(pred, target, num_classes):\n",
    "    inter = np.zeros(num_classes); union = np.zeros(num_classes)\n",
    "    for c in range(num_classes):\n",
    "        p, t = (pred==c), (target==c)\n",
    "        inter[c] = np.logical_and(p,t).sum()\n",
    "        union[c] = np.logical_or(p,t).sum()\n",
    "    return inter, union\n",
    "\n",
    "def evaluate_miou(model, dataloader, num_classes, device):\n",
    "    model.eval(); inters, unions = np.zeros(num_classes), np.zeros(num_classes)\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, leave=False):\n",
    "            if batch is None: continue\n",
    "            imgs, masks = batch['image'].to(device), batch['mask'].to(device)\n",
    "            preds = torch.argmax(model(imgs), dim=1).cpu().numpy().ravel()\n",
    "            gts = masks.cpu().numpy().ravel()\n",
    "            inter, union = intersection_and_union(preds, gts, num_classes)\n",
    "            inters += inter; unions += union\n",
    "    ious = np.divide(inters, unions, out=np.zeros_like(inters), where=unions>0)\n",
    "    return float(np.nanmean(ious))\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_accuracy(model, dataloader, device):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    for batch in tqdm(dataloader, leave=False):\n",
    "        if batch is None:\n",
    "            continue\n",
    "        imgs  = batch['image'].to(device)\n",
    "        masks = batch['mask'].to(device).long()\n",
    "        logits = model(imgs)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        correct += (preds == masks).sum().item()\n",
    "        total   += masks.numel()\n",
    "    return correct, total\n",
    "\n",
    "def safe_div(n, d):\n",
    "    return (n / d) if d > 0 else 0.0\n",
    "\n",
    "def load_pretrained(model, path):\n",
    "    ckpt = torch.load(path, map_location='cpu')\n",
    "    if 'model_state_dict' in ckpt: ckpt = ckpt['model_state_dict']\n",
    "    state = OrderedDict()\n",
    "    for k,v in ckpt.items():\n",
    "        k2 = k.replace('module.','')\n",
    "        if 'clf_conv' not in k2: state[k2] = v\n",
    "    model.load_state_dict(state, strict=False)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_dataset(name):\n",
    "    print(f\"\\nðŸŸ¢ Training on {name} dataset...\")\n",
    "    train_ds = build_split_dataset(name, 'train')\n",
    "    val_ds   = build_split_dataset(name, 'val')\n",
    "    train_loader = DataLoader(train_ds, BATCH_SIZE, True, collate_fn=collate_skip_none)\n",
    "    val_loader   = DataLoader(val_ds, BATCH_SIZE, False, collate_fn=collate_skip_none)\n",
    "\n",
    "    model = rf101(num_classes=NUM_CLASSES)\n",
    "    model = load_pretrained(model, PRETRAINED_WEIGHTS)\n",
    "    model.clf_conv = nn.Conv2d(256, NUM_CLASSES, 3, 1, 1)\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    opt = optim.Adam(model.parameters(), lr=LR)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_miou = -1\n",
    "    save_path_best = os.path.join(OUTPUT_DIR, f'{name}_best.pth.tar')\n",
    "    save_path_last = os.path.join(OUTPUT_DIR, f'{name}_last.pth.tar')\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train(); total_loss = 0\n",
    "        for batch in tqdm(train_loader, desc=f\"{name} | Epoch {epoch+1}/{EPOCHS}\", leave=False):\n",
    "            if batch is None: continue\n",
    "            imgs, masks = batch['image'].to(DEVICE), batch['mask'].to(DEVICE)\n",
    "            opt.zero_grad(); out = model(imgs)\n",
    "            loss = criterion(out, masks)\n",
    "            loss.backward(); opt.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        val_miou = evaluate_miou(model, val_loader, NUM_CLASSES, DEVICE)\n",
    "        print(f\"{name} | Epoch {epoch+1}: Loss={total_loss/len(train_loader):.4f}, Val mIoU={val_miou:.4f}\")\n",
    "\n",
    "        checkpoint_data = {\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'val_miou': val_miou,\n",
    "            'loss': total_loss/len(train_loader)\n",
    "        }\n",
    "\n",
    "        torch.save(checkpoint_data, save_path_last)\n",
    "\n",
    "        if val_miou > best_miou:\n",
    "            best_miou = val_miou\n",
    "            torch.save(checkpoint_data, save_path_best)\n",
    "            print(f\"âœ… Saved best model for {name} with mIoU={val_miou:.4f}\")\n",
    "\n",
    "    print(f\"ðŸŸ© Finished training {name}. Best Val mIoU={best_miou:.4f}\")\n",
    "    print(f\"   Best model saved to: {save_path_best}\")\n",
    "    print(f\"   Last model saved to: {save_path_last}\")\n",
    "    return save_path_best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cross_evaluation():\n",
    "    print(\"\\n========================================================\")\n",
    "    print(\"ðŸ”· Starting Cross-Dataset Evaluation...\")\n",
    "    print(\"========================================================\")\n",
    "\n",
    "    results = np.zeros((len(DATASETS), len(DATASETS)))\n",
    "    acc_counts = {train_ds: {test_ds: (0, 0) for test_ds in DATASETS} for train_ds in DATASETS}\n",
    "\n",
    "    for i, train_ds in enumerate(DATASETS):\n",
    "        print(f\"\\nðŸ”· Evaluating model trained on {train_ds}\")\n",
    "        model_path = os.path.join(OUTPUT_DIR, f'{train_ds}_best.pth.tar')\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"   [!] WARNING: Best model not found at {model_path}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        model = rf101(NUM_CLASSES)\n",
    "        ck = torch.load(model_path, map_location=DEVICE)\n",
    "        model.load_state_dict(ck['model_state_dict'])\n",
    "        model = model.to(DEVICE)\n",
    "        model.eval()\n",
    "\n",
    "        for j, test_ds in enumerate(DATASETS):\n",
    "            print(f\"   Testing on {test_ds}...\")\n",
    "            test_data   = build_split_dataset(test_ds, 'test')\n",
    "            test_loader = DataLoader(test_data, BATCH_SIZE, False, collate_fn=collate_skip_none)\n",
    "\n",
    "            miou = evaluate_miou(model, test_loader, NUM_CLASSES, DEVICE)\n",
    "            results[i, j] = miou\n",
    "            print(f\"   {train_ds} â†’ {test_ds} : mIoU = {miou:.4f}\")\n",
    "            \n",
    "            correct, total = evaluate_accuracy(model, test_loader, DEVICE)\n",
    "            acc_counts[train_ds][test_ds] = (correct, total)\n",
    "            print(f\"      (acc = {safe_div(correct, total):.4f})\")\n",
    "\n",
    "    print(\"\\n====================  FINAL  mIoU  MATRIX  ====================\")\n",
    "    print(\"Rows = trained on, Columns = tested on\\n\")\n",
    "    print(\"        \" + \"  \".join([f\"{d[:10]:>10}\" for d in DATASETS]))\n",
    "    for i, train_ds in enumerate(DATASETS):\n",
    "        row = \"  \".join([f\"{results[i,j]:10.4f}\" for j in range(len(DATASETS))])\n",
    "        print(f\"{train_ds[:10]:>10}  {row}\")\n",
    "\n",
    "    np.save(os.path.join(OUTPUT_DIR, \"cross_dataset_mIoU_5x5.npy\"), results)\n",
    "    print(f\"\\nMatrix saved to {OUTPUT_DIR}/cross_dataset_mIoU_5x5.npy\")\n",
    "\n",
    "    print(\"\\n====================  PER-MODEL ACCURACIES  ====================\")\n",
    "    print(\"Format: own_test | other_tests_combined | all_tests_combined\\n\")\n",
    "\n",
    "    for train_ds in DATASETS:\n",
    "        own_correct, own_total = acc_counts[train_ds][train_ds]\n",
    "\n",
    "        other_correct, other_total = 0, 0\n",
    "        for test_ds in DATASETS:\n",
    "            if test_ds == train_ds:\n",
    "                continue\n",
    "            c, t = acc_counts[train_ds][test_ds]\n",
    "            other_correct += c\n",
    "            other_total   += t\n",
    "\n",
    "        all_correct = own_correct + other_correct\n",
    "        all_total   = own_total   + other_total\n",
    "\n",
    "        own_acc   = safe_div(own_correct,   own_total)\n",
    "        other_acc = safe_div(other_correct, other_total)\n",
    "        all_acc   = safe_div(all_correct,   all_total)\n",
    "\n",
    "        print(f\"{train_ds:>12}: {own_acc:.4f} | {other_acc:.4f} | {all_acc:.4f}\")\n",
    "\n",
    "    print(\"\\nâœ… Cross-evaluation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŸ¢ Training on egohands dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "egohands | Epoch 1: Loss=0.0538, Val mIoU=0.9013\n",
      "âœ… Saved best model for egohands with mIoU=0.9013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "egohands | Epoch 2: Loss=0.0334, Val mIoU=0.9114\n",
      "âœ… Saved best model for egohands with mIoU=0.9114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "egohands | Epoch 3: Loss=0.0295, Val mIoU=0.9154\n",
      "âœ… Saved best model for egohands with mIoU=0.9154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "egohands | Epoch 4: Loss=0.0275, Val mIoU=0.9163\n",
      "âœ… Saved best model for egohands with mIoU=0.9163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "egohands | Epoch 5: Loss=0.0267, Val mIoU=0.9183\n",
      "âœ… Saved best model for egohands with mIoU=0.9183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "egohands | Epoch 6: Loss=0.0249, Val mIoU=0.9180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "egohands | Epoch 7: Loss=0.0240, Val mIoU=0.9175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "egohands | Epoch 8: Loss=0.0228, Val mIoU=0.9192\n",
      "âœ… Saved best model for egohands with mIoU=0.9192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "egohands | Epoch 9: Loss=0.0220, Val mIoU=0.9205\n",
      "âœ… Saved best model for egohands with mIoU=0.9205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "egohands | Epoch 10: Loss=0.0211, Val mIoU=0.9221\n",
      "âœ… Saved best model for egohands with mIoU=0.9221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "egohands | Epoch 11: Loss=0.0204, Val mIoU=0.9216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "egohands | Epoch 12: Loss=0.0203, Val mIoU=0.9198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "egohands | Epoch 13: Loss=0.0198, Val mIoU=0.9216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "egohands | Epoch 14: Loss=0.0188, Val mIoU=0.9186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "egohands | Epoch 15: Loss=0.0193, Val mIoU=0.9202\n",
      "ðŸŸ© Finished training egohands. Best Val mIoU=0.9221\n",
      "   Best model saved to: /teamspace/studios/this_studio/models_checkpoints/egohands_best.pth.tar\n",
      "   Last model saved to: /teamspace/studios/this_studio/models_checkpoints/egohands_last.pth.tar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/teamspace/studios/this_studio/models_checkpoints/egohands_best.pth.tar'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_on_dataset('egohands')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŸ¢ Training on ego_youtube_hands dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ego_youtube_hands | Epoch 1: Loss=0.1159, Val mIoU=0.4966\n",
      "âœ… Saved best model for ego_youtube_hands with mIoU=0.4966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ego_youtube_hands | Epoch 2: Loss=0.0504, Val mIoU=0.7413\n",
      "âœ… Saved best model for ego_youtube_hands with mIoU=0.7413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ego_youtube_hands | Epoch 3: Loss=0.0337, Val mIoU=0.7712\n",
      "âœ… Saved best model for ego_youtube_hands with mIoU=0.7712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ego_youtube_hands | Epoch 4: Loss=0.0250, Val mIoU=0.7838\n",
      "âœ… Saved best model for ego_youtube_hands with mIoU=0.7838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ego_youtube_hands | Epoch 5: Loss=0.0225, Val mIoU=0.7993\n",
      "âœ… Saved best model for ego_youtube_hands with mIoU=0.7993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ego_youtube_hands | Epoch 6: Loss=0.0188, Val mIoU=0.7993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ego_youtube_hands | Epoch 7: Loss=0.0170, Val mIoU=0.8115\n",
      "âœ… Saved best model for ego_youtube_hands with mIoU=0.8115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ego_youtube_hands | Epoch 8: Loss=0.0152, Val mIoU=0.8077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ego_youtube_hands | Epoch 9: Loss=0.0144, Val mIoU=0.8113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ego_youtube_hands | Epoch 10: Loss=0.0143, Val mIoU=0.8206\n",
      "âœ… Saved best model for ego_youtube_hands with mIoU=0.8206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ego_youtube_hands | Epoch 11: Loss=0.0142, Val mIoU=0.8038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ego_youtube_hands | Epoch 12: Loss=0.0133, Val mIoU=0.8111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ego_youtube_hands | Epoch 13: Loss=0.0129, Val mIoU=0.8139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ego_youtube_hands | Epoch 14: Loss=0.0116, Val mIoU=0.8110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ego_youtube_hands | Epoch 15: Loss=0.0109, Val mIoU=0.8180\n",
      "ðŸŸ© Finished training ego_youtube_hands. Best Val mIoU=0.8206\n",
      "   Best model saved to: /teamspace/studios/this_studio/models_checkpoints/ego_youtube_hands_best.pth.tar\n",
      "   Last model saved to: /teamspace/studios/this_studio/models_checkpoints/ego_youtube_hands_last.pth.tar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/teamspace/studios/this_studio/models_checkpoints/ego_youtube_hands_best.pth.tar'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#batch size 16\n",
    "\n",
    "train_on_dataset('ego_youtube_hands')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŸ¢ Training on ego_youtube_hands dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ego_youtube_hands | Epoch 1: Loss=0.0870, Val mIoU=0.7132\n",
      "âœ… Saved best model for ego_youtube_hands with mIoU=0.7132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ego_youtube_hands | Epoch 2: Loss=0.0383, Val mIoU=0.7717\n",
      "âœ… Saved best model for ego_youtube_hands with mIoU=0.7717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ego_youtube_hands | Epoch 3: Loss=0.0274, Val mIoU=0.8119\n",
      "âœ… Saved best model for ego_youtube_hands with mIoU=0.8119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ego_youtube_hands | Epoch 4: Loss=0.0230, Val mIoU=0.8233\n",
      "âœ… Saved best model for ego_youtube_hands with mIoU=0.8233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ego_youtube_hands | Epoch 5: Loss=0.0203, Val mIoU=0.8376\n",
      "âœ… Saved best model for ego_youtube_hands with mIoU=0.8376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ego_youtube_hands | Epoch 6: Loss=0.0160, Val mIoU=0.8378\n",
      "âœ… Saved best model for ego_youtube_hands with mIoU=0.8378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ego_youtube_hands | Epoch 7: Loss=0.0146, Val mIoU=0.8282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ego_youtube_hands | Epoch 8: Loss=0.0139, Val mIoU=0.8405\n",
      "âœ… Saved best model for ego_youtube_hands with mIoU=0.8405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ego_youtube_hands | Epoch 9: Loss=0.0128, Val mIoU=0.8438\n",
      "âœ… Saved best model for ego_youtube_hands with mIoU=0.8438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ego_youtube_hands | Epoch 10: Loss=0.0135, Val mIoU=0.8173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ego_youtube_hands | Epoch 11: Loss=0.0133, Val mIoU=0.8295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ego_youtube_hands | Epoch 12: Loss=0.0111, Val mIoU=0.8394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ego_youtube_hands | Epoch 13: Loss=0.0112, Val mIoU=0.8412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ego_youtube_hands | Epoch 14: Loss=0.0152, Val mIoU=0.8087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ego_youtube_hands | Epoch 15: Loss=0.0191, Val mIoU=0.8028\n",
      "ðŸŸ© Finished training ego_youtube_hands. Best Val mIoU=0.8438\n",
      "   Best model saved to: /teamspace/studios/this_studio/models_checkpoints/ego_youtube_hands_best.pth.tar\n",
      "   Last model saved to: /teamspace/studios/this_studio/models_checkpoints/ego_youtube_hands_last.pth.tar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/teamspace/studios/this_studio/models_checkpoints/ego_youtube_hands_best.pth.tar'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#batch size = 4\n",
    "train_on_dataset('ego_youtube_hands')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŸ¢ Training on gtea dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtea | Epoch 1: Loss=0.0832, Val mIoU=0.8571\n",
      "âœ… Saved best model for gtea with mIoU=0.8571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtea | Epoch 2: Loss=0.0370, Val mIoU=0.8797\n",
      "âœ… Saved best model for gtea with mIoU=0.8797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtea | Epoch 3: Loss=0.0301, Val mIoU=0.8765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtea | Epoch 4: Loss=0.0297, Val mIoU=0.8593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtea | Epoch 5: Loss=0.0358, Val mIoU=0.8838\n",
      "âœ… Saved best model for gtea with mIoU=0.8838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtea | Epoch 6: Loss=0.0271, Val mIoU=0.8779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtea | Epoch 7: Loss=0.0246, Val mIoU=0.8728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtea | Epoch 8: Loss=0.0273, Val mIoU=0.8785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtea | Epoch 9: Loss=0.0366, Val mIoU=0.8774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtea | Epoch 10: Loss=0.0271, Val mIoU=0.8898\n",
      "âœ… Saved best model for gtea with mIoU=0.8898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtea | Epoch 11: Loss=0.1238, Val mIoU=0.8791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtea | Epoch 12: Loss=0.0316, Val mIoU=0.8817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtea | Epoch 13: Loss=0.0272, Val mIoU=0.8881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtea | Epoch 14: Loss=0.0246, Val mIoU=0.8868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtea | Epoch 15: Loss=0.0210, Val mIoU=0.8902\n",
      "âœ… Saved best model for gtea with mIoU=0.8902\n",
      "ðŸŸ© Finished training gtea. Best Val mIoU=0.8902\n",
      "   Best model saved to: /teamspace/studios/this_studio/models_checkpoints/gtea_best.pth.tar\n",
      "   Last model saved to: /teamspace/studios/this_studio/models_checkpoints/gtea_last.pth.tar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/teamspace/studios/this_studio/models_checkpoints/gtea_best.pth.tar'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#batch size = 4\n",
    "train_on_dataset('gtea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŸ¢ Training on gtea dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtea | Epoch 1: Loss=0.1308, Val mIoU=0.8408\n",
      "âœ… Saved best model for gtea with mIoU=0.8408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtea | Epoch 2: Loss=0.0434, Val mIoU=0.8699\n",
      "âœ… Saved best model for gtea with mIoU=0.8699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtea | Epoch 3: Loss=0.0344, Val mIoU=0.8661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtea | Epoch 4: Loss=0.0289, Val mIoU=0.8832\n",
      "âœ… Saved best model for gtea with mIoU=0.8832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtea | Epoch 5: Loss=0.0282, Val mIoU=0.8855\n",
      "âœ… Saved best model for gtea with mIoU=0.8855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtea | Epoch 6: Loss=0.0241, Val mIoU=0.8844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtea | Epoch 7: Loss=0.0227, Val mIoU=0.8859\n",
      "âœ… Saved best model for gtea with mIoU=0.8859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtea | Epoch 8: Loss=0.0220, Val mIoU=0.8861\n",
      "âœ… Saved best model for gtea with mIoU=0.8861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtea | Epoch 9: Loss=0.0202, Val mIoU=0.8875\n",
      "âœ… Saved best model for gtea with mIoU=0.8875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtea | Epoch 10: Loss=0.0208, Val mIoU=0.8879\n",
      "âœ… Saved best model for gtea with mIoU=0.8879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtea | Epoch 11: Loss=0.0202, Val mIoU=0.8869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtea | Epoch 12: Loss=0.0195, Val mIoU=0.8855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtea | Epoch 13: Loss=0.0186, Val mIoU=0.8879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtea | Epoch 14: Loss=0.0181, Val mIoU=0.8901\n",
      "âœ… Saved best model for gtea with mIoU=0.8901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtea | Epoch 15: Loss=0.0181, Val mIoU=0.8855\n",
      "ðŸŸ© Finished training gtea. Best Val mIoU=0.8901\n",
      "   Best model saved to: /teamspace/studios/this_studio/models_checkpoints/gtea_best.pth.tar\n",
      "   Last model saved to: /teamspace/studios/this_studio/models_checkpoints/gtea_last.pth.tar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/teamspace/studios/this_studio/models_checkpoints/gtea_best.pth.tar'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#batch size = 16\n",
    "train_on_dataset('gtea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch size 16\n",
    "train_on_dataset('hand_over_face')\n",
    "\n",
    "\n",
    "# ðŸŸ¢ Training on hand_over_face dataset...\n",
    "                                                                            \n",
    "# hand_over_face | Epoch 1: Loss=0.2744, Val mIoU=0.4835\n",
    "# âœ… Saved best model for hand_over_face with mIoU=0.4835\n",
    "                                                                            \n",
    "# hand_over_face | Epoch 2: Loss=0.1648, Val mIoU=0.6855\n",
    "# âœ… Saved best model for hand_over_face with mIoU=0.6855\n",
    "                                                                            \n",
    "# hand_over_face | Epoch 3: Loss=0.1087, Val mIoU=0.7124\n",
    "# âœ… Saved best model for hand_over_face with mIoU=0.7124\n",
    "                                                                            \n",
    "# hand_over_face | Epoch 4: Loss=0.0861, Val mIoU=0.7709\n",
    "# âœ… Saved best model for hand_over_face with mIoU=0.7709\n",
    "                                                                            \n",
    "# hand_over_face | Epoch 5: Loss=0.0568, Val mIoU=0.7996\n",
    "# âœ… Saved best model for hand_over_face with mIoU=0.7996\n",
    "                                                                            \n",
    "# hand_over_face | Epoch 6: Loss=0.0433, Val mIoU=0.8270\n",
    "# âœ… Saved best model for hand_over_face with mIoU=0.8270\n",
    "                                                                            \n",
    "# hand_over_face | Epoch 7: Loss=0.0349, Val mIoU=0.8150\n",
    "                                                                            \n",
    "# hand_over_face | Epoch 8: Loss=0.0314, Val mIoU=0.8110\n",
    "                                                                            \n",
    "# hand_over_face | Epoch 9: Loss=0.0282, Val mIoU=0.8185\n",
    "                                                                             \n",
    "# hand_over_face | Epoch 10: Loss=0.0254, Val mIoU=0.8129\n",
    "                                                                             \n",
    "# hand_over_face | Epoch 11: Loss=0.0233, Val mIoU=0.8184\n",
    "                                                                             \n",
    "# hand_over_face | Epoch 12: Loss=0.0218, Val mIoU=0.8085\n",
    "                                                                             \n",
    "# hand_over_face | Epoch 13: Loss=0.0200, Val mIoU=0.8211\n",
    "                                                                             \n",
    "# hand_over_face | Epoch 14: Loss=0.0197, Val mIoU=0.8089\n",
    "                                                                             \n",
    "# hand_over_face | Epoch 15: Loss=0.0194, Val mIoU=0.8129\n",
    "# ðŸŸ© Finished training hand_over_face. Best Val mIoU=0.8270\n",
    "#    Best model saved to: /teamspace/studios/this_studio/models_checkpoints/hand_over_face_best.pth.tar\n",
    "#    Last model saved to: /teamspace/studios/this_studio/models_checkpoints/hand_over_face_last.pth.tar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŸ¢ Training on hand_over_face dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hand_over_face | Epoch 1: Loss=0.2267, Val mIoU=0.6070\n",
      "âœ… Saved best model for hand_over_face with mIoU=0.6070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hand_over_face | Epoch 2: Loss=0.1189, Val mIoU=0.6745\n",
      "âœ… Saved best model for hand_over_face with mIoU=0.6745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hand_over_face | Epoch 3: Loss=0.0749, Val mIoU=0.7869\n",
      "âœ… Saved best model for hand_over_face with mIoU=0.7869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hand_over_face | Epoch 4: Loss=0.0577, Val mIoU=0.7791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hand_over_face | Epoch 5: Loss=0.0493, Val mIoU=0.7603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hand_over_face | Epoch 6: Loss=0.0385, Val mIoU=0.8099\n",
      "âœ… Saved best model for hand_over_face with mIoU=0.8099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hand_over_face | Epoch 7: Loss=0.0346, Val mIoU=0.8266\n",
      "âœ… Saved best model for hand_over_face with mIoU=0.8266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hand_over_face | Epoch 8: Loss=0.0286, Val mIoU=0.8230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hand_over_face | Epoch 9: Loss=0.0244, Val mIoU=0.7879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hand_over_face | Epoch 10: Loss=0.0273, Val mIoU=0.7962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hand_over_face | Epoch 11: Loss=0.0353, Val mIoU=0.7851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hand_over_face | Epoch 12: Loss=0.0267, Val mIoU=0.8006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hand_over_face | Epoch 13: Loss=0.0234, Val mIoU=0.7853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hand_over_face | Epoch 14: Loss=0.0245, Val mIoU=0.7393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hand_over_face | Epoch 15: Loss=0.0307, Val mIoU=0.7480\n",
      "ðŸŸ© Finished training hand_over_face. Best Val mIoU=0.8266\n",
      "   Best model saved to: /teamspace/studios/this_studio/models_checkpoints/hand_over_face_best.pth.tar\n",
      "   Last model saved to: /teamspace/studios/this_studio/models_checkpoints/hand_over_face_last.pth.tar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/teamspace/studios/this_studio/models_checkpoints/hand_over_face_best.pth.tar'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#batch size 4\n",
    "\n",
    "train_on_dataset('hand_over_face')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified intersection_and_union function (Code Cell 15.1)\n",
    "def intersection_and_union_all_metrics(pred, target, num_classes):\n",
    "    inter = np.zeros(num_classes)\n",
    "    union = np.zeros(num_classes)\n",
    "    tp = np.zeros(num_classes) # True Positives\n",
    "    fp = np.zeros(num_classes) # False Positives\n",
    "    fn = np.zeros(num_classes) # False Negatives\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        p, t = (pred == c), (target == c)\n",
    "        \n",
    "        # Intersection and Union for IoU\n",
    "        inter[c] = np.logical_and(p, t).sum()\n",
    "        union[c] = np.logical_or(p, t).sum()\n",
    "        \n",
    "        # TP, FP, FN for Precision and Recall\n",
    "        tp[c] = np.logical_and(p, t).sum() # Correctly predicted as class C\n",
    "        fp[c] = np.logical_and(p, np.logical_not(t)).sum() # Predicted as C, but is not C\n",
    "        fn[c] = np.logical_and(np.logical_not(p), t).sum() # Not predicted as C, but is C\n",
    "\n",
    "    return inter, union, tp, fp, fn\n",
    "\n",
    "# Modified evaluate_miou (Code Cell 15.2)\n",
    "# Renaming and updating to handle all metrics\n",
    "def evaluate_metrics(model, dataloader, num_classes, device):\n",
    "    model.eval()\n",
    "    inters, unions, tps, fps, fns = (np.zeros(num_classes) for _ in range(5))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, leave=False):\n",
    "            if batch is None: continue\n",
    "            imgs, masks = batch['image'].to(device), batch['mask'].to(device)\n",
    "            # Flatten predictions and ground truth\n",
    "            preds = torch.argmax(model(imgs), dim=1).cpu().numpy().ravel()\n",
    "            gts = masks.cpu().numpy().ravel()\n",
    "            \n",
    "            inter, union, tp, fp, fn = intersection_and_union_all_metrics(preds, gts, num_classes)\n",
    "            inters += inter\n",
    "            unions += union\n",
    "            tps += tp\n",
    "            fps += fp\n",
    "            fns += fn\n",
    "    \n",
    "    # Calculate per-class metrics\n",
    "    ious = np.divide(inters, unions, out=np.zeros_like(inters), where=unions > 0)\n",
    "    precisions = np.divide(tps, tps + fps, out=np.zeros_like(tps), where=(tps + fps) > 0)\n",
    "    recalls = np.divide(tps, tps + fns, out=np.zeros_like(tps), where=(tps + fns) > 0)\n",
    "    \n",
    "    # Calculate mean metrics (skipping background class c=0 if num_classes > 1)\n",
    "    # Background class c=0, Hand class c=1\n",
    "    \n",
    "    if num_classes > 1:\n",
    "        # Calculate mean for the foreground class(es), typically 1 to num_classes-1\n",
    "        miou = float(np.nanmean(ious[1:]))\n",
    "        mprecision = float(np.nanmean(precisions[1:]))\n",
    "        mrecall = float(np.nanmean(recalls[1:]))\n",
    "    else:\n",
    "        # For single class segmentation, just use the only class (class 0)\n",
    "        miou = float(np.nanmean(ious))\n",
    "        mprecision = float(np.nanmean(precisions))\n",
    "        mrecall = float(np.nanmean(recalls))\n",
    "\n",
    "    return miou, mprecision, mrecall, tps, fns, fps, unions\n",
    "\n",
    "# Helper function to find mask extension for the dataset (Code Cell 15.3)\n",
    "def get_mask_ext(dataset_name):\n",
    "    # Based on your note: 'gtea masks are jpg, others are png'\n",
    "    return '.jpg' if dataset_name == 'gtea' else '.png'\n",
    "\n",
    "\n",
    "# Updated HandSegmentationDataset for correct mask extension (Code Cell 15.4)\n",
    "class HandSegmentationDataset(Dataset):\n",
    "    def __init__(self, img_root, mask_root, split='train', mask_ext='.jpg'):\n",
    "        self.img_dir = os.path.join(img_root, split)\n",
    "        self.mask_dir = os.path.join(mask_root, split)\n",
    "        self.files = [f for f in os.listdir(self.img_dir) if f.lower().endswith(('jpg', 'png', 'jpeg'))]\n",
    "        self.mask_ext = mask_ext\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_file_base = self.files[idx].rsplit('.',1)[0]\n",
    "        \n",
    "        img_path = os.path.join(self.img_dir, self.files[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, img_file_base + self.mask_ext)\n",
    "        \n",
    "        try:\n",
    "            image = np.array(Image.open(img_path).convert('RGB').resize(IMG_SIZE, Image.BILINEAR)).astype(np.float32)/255.\n",
    "            mask = np.array(Image.open(mask_path).convert('L').resize(IMG_SIZE, Image.NEAREST))\n",
    "            mask = (mask>0).astype(np.int64)\n",
    "            norm = (image - IMG_MEAN)/IMG_STD\n",
    "            img_tensor = torch.tensor(norm.transpose(2,0,1)).float()\n",
    "            mask_tensor = torch.tensor(mask).long()\n",
    "            return {'image': img_tensor, 'mask': mask_tensor}\n",
    "        except FileNotFoundError:\n",
    "            # Handle cases where a corresponding mask file might be missing\n",
    "            # Should not happen in a clean dataset, but good for robustness\n",
    "            print(f\"File not found: {mask_path} (Img: {img_path}). Skipping.\")\n",
    "            return None\n",
    "\n",
    "\n",
    "# Updated build_split_dataset (Code Cell 15.5)\n",
    "def build_split_dataset(name, split):\n",
    "    if name != 'combined4':\n",
    "        img_dir  = os.path.join(HAND_SPLIT_BASE, name, 'images_splitted')\n",
    "        mask_dir = os.path.join(HAND_SPLIT_BASE, name, 'masks_splitted')\n",
    "        mask_ext = get_mask_ext(name) # Get correct extension\n",
    "        return HandSegmentationDataset(img_dir, mask_dir, split, mask_ext=mask_ext)\n",
    "    else:\n",
    "        parts = []\n",
    "        for d in BASE_DATASETS:\n",
    "            img_dir  = os.path.join(HAND_SPLIT_BASE, d, 'images_splitted')\n",
    "            mask_dir = os.path.join(HAND_SPLIT_BASE, d, 'masks_splitted')\n",
    "            mask_ext = get_mask_ext(d) # Get correct extension\n",
    "            parts.append(HandSegmentationDataset(img_dir, mask_dir, split, mask_ext=mask_ext))\n",
    "        return ConcatDataset(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: New Cross-Evaluation Function\n",
    "import pandas as pd\n",
    "\n",
    "# Only consider models trained on individual datasets\n",
    "train_datasets = BASE_DATASETS  # ['egohands', 'ego_youtube_hands', 'gtea', 'hand_over_face']\n",
    "test_datasets = DATASETS       # ['egohands', 'ego_youtube_hands', 'gtea', 'hand_over_face', 'combined4']\n",
    "\n",
    "def run_new_cross_evaluation():\n",
    "    print(\"\\n=========================================================================\")\n",
    "    print(\"ðŸ”· Starting Cross-Dataset Evaluation (mIoU, mRecall, mPrecision)...\")\n",
    "    print(\"=========================================================================\")\n",
    "\n",
    "    all_results = []\n",
    "    \n",
    "    for i, train_ds in enumerate(train_datasets):\n",
    "        print(f\"\\nðŸ”· Evaluating model trained on {train_ds}\")\n",
    "        model_path = os.path.join(OUTPUT_DIR, f'{train_ds}_best.pth.tar')\n",
    "        \n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"   [!] WARNING: Best model not found at {model_path}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Load model and weights\n",
    "        model = rf101(NUM_CLASSES)\n",
    "        ck = torch.load(model_path, map_location=DEVICE)\n",
    "        model.load_state_dict(ck['model_state_dict'])\n",
    "        model = model.to(DEVICE)\n",
    "        model.eval()\n",
    "\n",
    "        # Initialize per-model combined test set totals\n",
    "        model_all_test_tps, model_all_test_fns, model_all_test_fps = np.zeros(NUM_CLASSES), np.zeros(NUM_CLASSES), np.zeros(NUM_CLASSES)\n",
    "        model_all_test_unions = np.zeros(NUM_CLASSES)\n",
    "\n",
    "        for j, test_ds in enumerate(BASE_DATASETS): # Iterate over individual test sets for aggregation\n",
    "            print(f\"   Testing on {test_ds}...\")\n",
    "            test_data   = build_split_dataset(test_ds, 'test')\n",
    "            test_loader = DataLoader(test_data, BATCH_SIZE, False, collate_fn=collate_skip_none)\n",
    "\n",
    "            miou, mprecision, mrecall, tps, fns, fps, unions = evaluate_metrics(model, test_loader, NUM_CLASSES, DEVICE)\n",
    "            \n",
    "            # Aggregate for the final \"combined4\" result\n",
    "            model_all_test_tps += tps\n",
    "            model_all_test_fns += fns\n",
    "            model_all_test_fps += fps\n",
    "            model_all_test_unions += unions\n",
    "            \n",
    "            print(f\"   {train_ds} â†’ {test_ds} : mIoU={miou:.4f}, mRecall={mrecall:.4f}, mPrecision={mprecision:.4f}\")\n",
    "            \n",
    "            # Store results for individual test sets\n",
    "            all_results.append({\n",
    "                'Trained On': train_ds,\n",
    "                'Tested On': test_ds,\n",
    "                'mIoU': miou,\n",
    "                'mRecall': mrecall,\n",
    "                'mPrecision': mprecision\n",
    "            })\n",
    "\n",
    "        # --- Calculate Combined Testset Results ---\n",
    "        print(f\"   Testing on combined testset (All 4)...\")\n",
    "        \n",
    "        # Calculate combined metrics from aggregated totals (c=1, the hand class)\n",
    "        tps_hand = model_all_test_tps[1]\n",
    "        fns_hand = model_all_test_fns[1]\n",
    "        fps_hand = model_all_test_fps[1]\n",
    "        unions_hand = model_all_test_unions[1]\n",
    "        inters_hand = tps_hand\n",
    "        \n",
    "        # Calculate metrics (only for hand class, as per original logic's miou[1:])\n",
    "        combined_miou = safe_div(inters_hand, unions_hand)\n",
    "        combined_mprecision = safe_div(tps_hand, tps_hand + fps_hand)\n",
    "        combined_mrecall = safe_div(tps_hand, tps_hand + fns_hand)\n",
    "        \n",
    "        print(f\"   {train_ds} â†’ combined4 : mIoU={combined_miou:.4f}, mRecall={combined_mrecall:.4f}, mPrecision={combined_mprecision:.4f}\")\n",
    "        \n",
    "        # Store results for 'combined4' test set\n",
    "        all_results.append({\n",
    "            'Trained On': train_ds,\n",
    "            'Tested On': 'combined4',\n",
    "            'mIoU': combined_miou,\n",
    "            'mRecall': combined_mrecall,\n",
    "            'mPrecision': combined_mprecision\n",
    "        })\n",
    "\n",
    "\n",
    "    # --- Save and Print Final Matrix ---\n",
    "    df = pd.DataFrame(all_results)\n",
    "    \n",
    "    # Pivot the table to create the cross-evaluation matrix for printing and select order\n",
    "    miou_matrix = df.pivot(index='Trained On', columns='Tested On', values='mIoU')[test_datasets]\n",
    "    recall_matrix = df.pivot(index='Trained On', columns='Tested On', values='mRecall')[test_datasets]\n",
    "    precision_matrix = df.pivot(index='Trained On', columns='Tested On', values='mPrecision')[test_datasets]\n",
    "    \n",
    "    # Save to CSV\n",
    "    csv_path = os.path.join(OUTPUT_DIR, \"cross_dataset_metrics_4x5.csv\")\n",
    "    df.to_csv(csv_path, index=False, float_format='%.4f')\n",
    "    print(f\"\\nâœ… All results saved to: {csv_path}\")\n",
    "\n",
    "    print(\"\\n========================= FINAL mIoU MATRIX =========================\")\n",
    "    print(\"Rows = Trained on, Columns = Tested on\\n\")\n",
    "    print(miou_matrix.to_string(float_format='%.4f'))\n",
    "    \n",
    "    print(\"\\n========================= FINAL mRecall MATRIX =========================\")\n",
    "    print(\"Rows = Trained on, Columns = Tested on\\n\")\n",
    "    print(recall_matrix.to_string(float_format='%.4f'))\n",
    "    \n",
    "    print(\"\\n========================= FINAL mPrecision MATRIX =========================\")\n",
    "    print(\"Rows = Trained on, Columns = Tested on\\n\")\n",
    "    print(precision_matrix.to_string(float_format='%.4f'))\n",
    "    \n",
    "    print(\"\\nâœ… Cross-evaluation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================================================\n",
      "ðŸ”· Starting Cross-Dataset Evaluation (mIoU, mRecall, mPrecision)...\n",
      "=========================================================================\n",
      "\n",
      "ðŸ”· Evaluating model trained on egohands\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Testing on egohands...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   egohands â†’ egohands : mIoU=0.8603, mRecall=0.9156, mPrecision=0.9343\n",
      "   Testing on ego_youtube_hands...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   egohands â†’ ego_youtube_hands : mIoU=0.2190, mRecall=0.4496, mPrecision=0.2993\n",
      "   Testing on gtea...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   egohands â†’ gtea : mIoU=0.7342, mRecall=0.8350, mPrecision=0.8589\n",
      "   Testing on hand_over_face...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   egohands â†’ hand_over_face : mIoU=0.4149, mRecall=0.7272, mPrecision=0.4914\n",
      "   Testing on combined testset (All 4)...\n",
      "   egohands â†’ combined4 : mIoU=0.7580, mRecall=0.8733, mPrecision=0.8517\n",
      "\n",
      "ðŸ”· Evaluating model trained on ego_youtube_hands\n",
      "   Testing on egohands...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ego_youtube_hands â†’ egohands : mIoU=0.2471, mRecall=0.2634, mPrecision=0.7999\n",
      "   Testing on ego_youtube_hands...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ego_youtube_hands â†’ ego_youtube_hands : mIoU=0.6356, mRecall=0.6974, mPrecision=0.8776\n",
      "   Testing on gtea...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ego_youtube_hands â†’ gtea : mIoU=0.1292, mRecall=0.1313, mPrecision=0.8906\n",
      "   Testing on hand_over_face...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ego_youtube_hands â†’ hand_over_face : mIoU=0.1217, mRecall=0.1322, mPrecision=0.6047\n",
      "   Testing on combined testset (All 4)...\n",
      "   ego_youtube_hands â†’ combined4 : mIoU=0.2346, mRecall=0.2484, mPrecision=0.8076\n",
      "\n",
      "ðŸ”· Evaluating model trained on gtea\n",
      "   Testing on egohands...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gtea â†’ egohands : mIoU=0.3104, mRecall=0.4315, mPrecision=0.5251\n",
      "   Testing on ego_youtube_hands...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gtea â†’ ego_youtube_hands : mIoU=0.0377, mRecall=0.0665, mPrecision=0.0800\n",
      "   Testing on gtea...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gtea â†’ gtea : mIoU=0.7824, mRecall=0.8339, mPrecision=0.9269\n",
      "   Testing on hand_over_face...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gtea â†’ hand_over_face : mIoU=0.0680, mRecall=0.1523, mPrecision=0.1094\n",
      "   Testing on combined testset (All 4)...\n",
      "   gtea â†’ combined4 : mIoU=0.3416, mRecall=0.4755, mPrecision=0.5482\n",
      "\n",
      "ðŸ”· Evaluating model trained on hand_over_face\n",
      "   Testing on egohands...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   hand_over_face â†’ egohands : mIoU=0.4383, mRecall=0.6357, mPrecision=0.5853\n",
      "   Testing on ego_youtube_hands...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   hand_over_face â†’ ego_youtube_hands : mIoU=0.2618, mRecall=0.3765, mPrecision=0.4620\n",
      "   Testing on gtea...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   hand_over_face â†’ gtea : mIoU=0.4100, mRecall=0.4387, mPrecision=0.8623\n",
      "   Testing on hand_over_face...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   hand_over_face â†’ hand_over_face : mIoU=0.7216, mRecall=0.8410, mPrecision=0.8357\n",
      "   Testing on combined testset (All 4)...\n",
      "   hand_over_face â†’ combined4 : mIoU=0.4406, mRecall=0.6016, mPrecision=0.6221\n",
      "\n",
      "âœ… All results saved to: /teamspace/studios/this_studio/models_checkpoints/cross_dataset_metrics_4x5.csv\n",
      "\n",
      "========================= FINAL mIoU MATRIX =========================\n",
      "Rows = Trained on, Columns = Tested on\n",
      "\n",
      "Tested On           gtea\n",
      "Trained On              \n",
      "ego_youtube_hands 0.1292\n",
      "egohands          0.7342\n",
      "gtea              0.7824\n",
      "hand_over_face    0.4100\n",
      "\n",
      "========================= FINAL mRecall MATRIX =========================\n",
      "Rows = Trained on, Columns = Tested on\n",
      "\n",
      "Tested On           gtea\n",
      "Trained On              \n",
      "ego_youtube_hands 0.1313\n",
      "egohands          0.8350\n",
      "gtea              0.8339\n",
      "hand_over_face    0.4387\n",
      "\n",
      "========================= FINAL mPrecision MATRIX =========================\n",
      "Rows = Trained on, Columns = Tested on\n",
      "\n",
      "Tested On           gtea\n",
      "Trained On              \n",
      "ego_youtube_hands 0.8906\n",
      "egohands          0.8589\n",
      "gtea              0.9269\n",
      "hand_over_face    0.8623\n",
      "\n",
      "âœ… Cross-evaluation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Cell: Run New Cross Evaluation\n",
    "run_new_cross_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from: /teamspace/studios/this_studio/models_checkpoints/cross_dataset_metrics_4x5.csv\n",
      "\n",
      "=========================================================================================\n",
      "Combined Cross-Evaluation Metrics Table\n",
      "Rows = Trained on, Columns = Tested on\n",
      "=========================================================================================\n",
      "                  egohands\\n(mIoU/mRec/mPre) ego_youtube_hands\\n(mIoU/mRec/mPre)    gtea\\n(mIoU/mRec/mPre) hand_over_face\\n(mIoU/mRec/mPre) combined4\\n(mIoU/mRec/mPre)\n",
      "egohands            0.8603 / 0.9156 / 0.9343            0.2190 / 0.4496 / 0.2993  0.7342 / 0.8350 / 0.8589         0.4149 / 0.7272 / 0.4914    0.7580 / 0.8733 / 0.8517\n",
      "ego_youtube_hands   0.3976 / 0.4510 / 0.7704            0.6033 / 0.7057 / 0.8061  0.2970 / 0.3047 / 0.9208         0.2322 / 0.2729 / 0.6091    0.3794 / 0.4243 / 0.7819\n",
      "gtea                0.4139 / 0.5678 / 0.6043            0.1632 / 0.1973 / 0.4861  0.7909 / 0.8279 / 0.9466         0.1182 / 0.1437 / 0.3991    0.4451 / 0.5779 / 0.6595\n",
      "hand_over_face      0.4484 / 0.5757 / 0.6698            0.2616 / 0.3293 / 0.5600  0.5386 / 0.5771 / 0.8898         0.6960 / 0.8068 / 0.8351    0.4682 / 0.5794 / 0.7092\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def safe_format(value):\n",
    "    \"\"\"Formats a float to 4 decimal places or returns '-' if NaN.\"\"\"\n",
    "    if pd.isna(value) or value is None:\n",
    "        return '-'\n",
    "    return f\"{value:.4f}\"\n",
    "\n",
    "def generate_combined_table(csv_path=\"/teamspace/studios/this_studio/models_checkpoints/cross_dataset_metrics_4x5.csv\"):\n",
    "    \"\"\"\n",
    "    Reads the cross-evaluation CSV, pivots the data for each metric, \n",
    "    and combines mIoU, mRecall, and mPrecision into a single formatted table,\n",
    "    with explicit metric headings in the column names.\n",
    "    \"\"\"\n",
    "    print(f\"Reading data from: {csv_path}\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: CSV file not found at {csv_path}. Please ensure the file exists.\")\n",
    "        return\n",
    "\n",
    "    # 1. Define the desired order for rows and columns\n",
    "    train_datasets_order = ['egohands', 'ego_youtube_hands', 'gtea', 'hand_over_face']\n",
    "    test_datasets_order = ['egohands', 'ego_youtube_hands', 'gtea', 'hand_over_face', 'combined4']\n",
    "    \n",
    "    # 2. Pivot the DataFrame for each metric\n",
    "    miou_pivot = df.pivot(index='Trained On', columns='Tested On', values='mIoU').fillna(np.nan)\n",
    "    mrecall_pivot = df.pivot(index='Trained On', columns='Tested On', values='mRecall').fillna(np.nan)\n",
    "    mprecision_pivot = df.pivot(index='Trained On', columns='Tested On', values='mPrecision').fillna(np.nan)\n",
    "\n",
    "    # 3. Reindex the pivoted tables to enforce the desired order\n",
    "    try:\n",
    "        miou_pivot = miou_pivot.reindex(index=train_datasets_order, columns=test_datasets_order)\n",
    "        mrecall_pivot = mrecall_pivot.reindex(index=train_datasets_order, columns=test_datasets_order)\n",
    "        mprecision_pivot = mprecision_pivot.reindex(index=train_datasets_order, columns=test_datasets_order)\n",
    "    except KeyError as e:\n",
    "        print(f\"Warning: Dataset names in CSV do not match expected names. Missing key: {e}. Using existing order.\")\n",
    "        pass\n",
    "        \n",
    "    # 4. Create the final combined DataFrame with formatted column headers\n",
    "    \n",
    "    # New column headers: Dataset Name \\n (mIoU/mRec/mPre)\n",
    "    new_columns = [f\"{ds}\\n(mIoU/mRec/mPre)\" for ds in test_datasets_order]\n",
    "    \n",
    "    combined_table = pd.DataFrame(index=train_datasets_order, columns=new_columns)\n",
    "\n",
    "    # Combine the metrics (mIoU / mRecall / mPrecision) into a single string for each cell\n",
    "    for i, train_ds in enumerate(train_datasets_order):\n",
    "        for j, test_ds in enumerate(test_datasets_order):\n",
    "            miou = miou_pivot.loc[train_ds, test_ds]\n",
    "            mrecall = mrecall_pivot.loc[train_ds, test_ds]\n",
    "            mprecision = mprecision_pivot.loc[train_ds, test_ds]\n",
    "            \n",
    "            # Format the output string: mIoU / mRecall / mPrecision\n",
    "            cell_content = (\n",
    "                f\"{safe_format(miou)} / \"\n",
    "                f\"{safe_format(mrecall)} / \"\n",
    "                f\"{safe_format(mprecision)}\"\n",
    "            )\n",
    "            # Use iloc to set values now that column names are complex strings\n",
    "            combined_table.iloc[i, j] = cell_content\n",
    "\n",
    "    print(\"\\n=========================================================================================\")\n",
    "    print(\"Combined Cross-Evaluation Metrics Table\")\n",
    "    print(\"Rows = Trained on, Columns = Tested on\")\n",
    "    print(\"=========================================================================================\")\n",
    "    # Using line_width=None helps pandas format the multi-line headers cleanly\n",
    "    print(combined_table.to_string(line_width=None))\n",
    "    print(\"=========================================================================================\")\n",
    "\n",
    "# Execute the function\n",
    "generate_combined_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from: /teamspace/studios/this_studio/models_checkpoints/cross_dataset_metrics_4x5.csv\n",
      "\n",
      "=========================================================================================\n",
      "Combined Cross-Evaluation Metrics Table\n",
      "Rows = Trained on, Columns = Tested on\n",
      "=========================================================================================\n",
      "                  egohands\\n(mIoU/mRec/mPre) ego_youtube_hands\\n(mIoU/mRec/mPre)    gtea\\n(mIoU/mRec/mPre) hand_over_face\\n(mIoU/mRec/mPre) combined4\\n(mIoU/mRec/mPre)\n",
      "egohands            0.8603 / 0.9156 / 0.9343            0.2190 / 0.4496 / 0.2993  0.7342 / 0.8350 / 0.8589         0.4149 / 0.7272 / 0.4914    0.7580 / 0.8733 / 0.8517\n",
      "ego_youtube_hands   0.2471 / 0.2634 / 0.7999            0.6356 / 0.6974 / 0.8776  0.1292 / 0.1313 / 0.8906         0.1217 / 0.1322 / 0.6047    0.2346 / 0.2484 / 0.8076\n",
      "gtea                0.3104 / 0.4315 / 0.5251            0.0377 / 0.0665 / 0.0800  0.7824 / 0.8339 / 0.9269         0.0680 / 0.1523 / 0.1094    0.3416 / 0.4755 / 0.5482\n",
      "hand_over_face      0.4383 / 0.6357 / 0.5853            0.2618 / 0.3765 / 0.4620  0.4100 / 0.4387 / 0.8623         0.7216 / 0.8410 / 0.8357    0.4406 / 0.6016 / 0.6221\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def safe_format(value):\n",
    "    \"\"\"Formats a float to 4 decimal places or returns '-' if NaN.\"\"\"\n",
    "    if pd.isna(value) or value is None:\n",
    "        return '-'\n",
    "    return f\"{value:.4f}\"\n",
    "\n",
    "def generate_combined_table(csv_path=\"/teamspace/studios/this_studio/models_checkpoints/cross_dataset_metrics_4x5.csv\"):\n",
    "    \"\"\"\n",
    "    Reads the cross-evaluation CSV, pivots the data for each metric, \n",
    "    and combines mIoU, mRecall, and mPrecision into a single formatted table,\n",
    "    with explicit metric headings in the column names.\n",
    "    \"\"\"\n",
    "    print(f\"Reading data from: {csv_path}\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: CSV file not found at {csv_path}. Please ensure the file exists.\")\n",
    "        return\n",
    "\n",
    "    # 1. Define the desired order for rows and columns\n",
    "    train_datasets_order = ['egohands', 'ego_youtube_hands', 'gtea', 'hand_over_face']\n",
    "    test_datasets_order = ['egohands', 'ego_youtube_hands', 'gtea', 'hand_over_face', 'combined4']\n",
    "    \n",
    "    # 2. Pivot the DataFrame for each metric\n",
    "    miou_pivot = df.pivot(index='Trained On', columns='Tested On', values='mIoU').fillna(np.nan)\n",
    "    mrecall_pivot = df.pivot(index='Trained On', columns='Tested On', values='mRecall').fillna(np.nan)\n",
    "    mprecision_pivot = df.pivot(index='Trained On', columns='Tested On', values='mPrecision').fillna(np.nan)\n",
    "\n",
    "    # 3. Reindex the pivoted tables to enforce the desired order\n",
    "    try:\n",
    "        miou_pivot = miou_pivot.reindex(index=train_datasets_order, columns=test_datasets_order)\n",
    "        mrecall_pivot = mrecall_pivot.reindex(index=train_datasets_order, columns=test_datasets_order)\n",
    "        mprecision_pivot = mprecision_pivot.reindex(index=train_datasets_order, columns=test_datasets_order)\n",
    "    except KeyError as e:\n",
    "        print(f\"Warning: Dataset names in CSV do not match expected names. Missing key: {e}. Using existing order.\")\n",
    "        pass\n",
    "        \n",
    "    # 4. Create the final combined DataFrame with formatted column headers\n",
    "    \n",
    "    # New column headers: Dataset Name \\n (mIoU/mRec/mPre)\n",
    "    new_columns = [f\"{ds}\\n(mIoU/mRec/mPre)\" for ds in test_datasets_order]\n",
    "    \n",
    "    combined_table = pd.DataFrame(index=train_datasets_order, columns=new_columns)\n",
    "\n",
    "    # Combine the metrics (mIoU / mRecall / mPrecision) into a single string for each cell\n",
    "    for i, train_ds in enumerate(train_datasets_order):\n",
    "        for j, test_ds in enumerate(test_datasets_order):\n",
    "            miou = miou_pivot.loc[train_ds, test_ds]\n",
    "            mrecall = mrecall_pivot.loc[train_ds, test_ds]\n",
    "            mprecision = mprecision_pivot.loc[train_ds, test_ds]\n",
    "            \n",
    "            # Format the output string: mIoU / mRecall / mPrecision\n",
    "            cell_content = (\n",
    "                f\"{safe_format(miou)} / \"\n",
    "                f\"{safe_format(mrecall)} / \"\n",
    "                f\"{safe_format(mprecision)}\"\n",
    "            )\n",
    "            # Use iloc to set values now that column names are complex strings\n",
    "            combined_table.iloc[i, j] = cell_content\n",
    "\n",
    "    print(\"\\n=========================================================================================\")\n",
    "    print(\"Combined Cross-Evaluation Metrics Table\")\n",
    "    print(\"Rows = Trained on, Columns = Tested on\")\n",
    "    print(\"=========================================================================================\")\n",
    "    # Using line_width=None helps pandas format the multi-line headers cleanly\n",
    "    print(combined_table.to_string(line_width=None))\n",
    "    print(\"=========================================================================================\")\n",
    "\n",
    "# Execute the function\n",
    "generate_combined_table()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
