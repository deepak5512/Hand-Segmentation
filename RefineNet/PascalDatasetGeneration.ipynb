{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Sg20UlhM384"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "import matplotlib as mpl\n",
        "from scipy.io import loadmat\n",
        "from skimage.measure import regionprops\n",
        "from skimage.io import imshow\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "from collections import defaultdict\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "BASE_DIR = '/content/drive/MyDrive/Pascal_dataset/'"
      ],
      "metadata": {
        "id": "YeaZ7y0-8ye3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98ad32b8-92be-4d46-b558-7e8ddd030685"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Classes in VOC 2010\n",
        "1: aeroplane, 2: bicycle, 3: bird, 4: boat, 5: bottle, 6: bus,\n",
        "7: car, 8: cat, 9: chair, 10: cow, 11: table, 12: dog,\n",
        "13: horse, 14: motorbike, 15: person, 16: pottedplant,\n",
        "17: sheep, 18: sofa, 19: train, 20: tvmonitor\n",
        "'''"
      ],
      "metadata": {
        "id": "9GUIKvV885HA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "115d88cd-2e97-44eb-cd60-1932b3bb90c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nClasses in VOC 2010\\n1: aeroplane, 2: bicycle, 3: bird, 4: boat, 5: bottle, 6: bus,\\n7: car, 8: cat, 9: chair, 10: cow, 11: table, 12: dog,\\n13: horse, 14: motorbike, 15: person, 16: pottedplant,\\n17: sheep, 18: sofa, 19: train, 20: tvmonitor\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pascal VOC color map (official format)\n",
        "def color_map(N=256, normalized=True):\n",
        "    def bitget(byteval, idx):\n",
        "        return ((byteval & (1 << idx)) != 0)\n",
        "\n",
        "    dtype = 'float32' if normalized else 'uint8'\n",
        "    cmap = np.zeros((N, 3), dtype=dtype)\n",
        "    for i in range(N):\n",
        "        r = g = b = 0\n",
        "        c = i\n",
        "        for j in range(8):\n",
        "            r = r | (bitget(c, 0) << (7 - j))\n",
        "            g = g | (bitget(c, 1) << (7 - j))\n",
        "            b = b | (bitget(c, 2) << (7 - j))\n",
        "            c = c >> 3\n",
        "        cmap[i] = np.array([r, g, b])\n",
        "    cmap = cmap / 255 if normalized else cmap\n",
        "    return LinearSegmentedColormap.from_list('voc_cmap', cmap)"
      ],
      "metadata": {
        "id": "pnkrQCZo85Db"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Pascal VOC color map\n",
        "VOC_CMAP = color_map(21)"
      ],
      "metadata": {
        "id": "vb5cjL2BLKLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_label(image_path, anno_path):\n",
        "    try:\n",
        "        image = plt.imread(image_path)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Warning: Image not found {image_path}\")\n",
        "        return 0, 0\n",
        "\n",
        "    image_size = image.shape\n",
        "    shape = image_size[:-1]\n",
        "\n",
        "    try:\n",
        "        mat_data = loadmat(anno_path)['anno'][0, 0]\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Warning: Annotation not found {anno_path}\")\n",
        "        return 0, 0\n",
        "\n",
        "    n_objects = mat_data['objects'].shape[1]\n",
        "    mask = np.zeros(shape, dtype=np.uint8)\n",
        "    found = False\n",
        "\n",
        "    for obj in mat_data['objects'][0, :]:\n",
        "        class_ind = obj['class_ind'][0, 0]\n",
        "\n",
        "        # Mark all pixels belonging to this objectâ€™s mask as its class index\n",
        "        if 'mask' in obj.dtype.names:\n",
        "            obj_mask = obj['mask']\n",
        "            mask[obj_mask > 0] = class_ind\n",
        "            found = True\n",
        "\n",
        "        # If it has parts, include them too (optional)\n",
        "        if obj['parts'].shape[1] > 0:\n",
        "            for part in obj['parts'][0, :]:\n",
        "                if 'mask' in part.dtype.names:\n",
        "                    part_mask = part['mask']\n",
        "                    mask[part_mask > 0] = class_ind\n",
        "                    found = True\n",
        "\n",
        "    return (image_size, mask) if found else (0, 0)"
      ],
      "metadata": {
        "id": "UsXHl80P848n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    print(f\"Using Base Directory: {BASE_DIR}\")\n",
        "\n",
        "    mat_dir = os.path.join(BASE_DIR, 'Annotations_Part/')\n",
        "    origimage_dir = os.path.join(BASE_DIR, 'JPEGImages/')\n",
        "    label_dir = os.path.join(BASE_DIR, 'masks_colored/')\n",
        "    image_dir = os.path.join(BASE_DIR, 'images/')\n",
        "\n",
        "    os.makedirs(label_dir, exist_ok=True)\n",
        "    os.makedirs(image_dir, exist_ok=True)\n",
        "\n",
        "    list_mats = os.listdir(mat_dir)\n",
        "    print(f\"Found {len(list_mats)} annotation files to process.\")\n",
        "\n",
        "    processed = skipped = 0\n",
        "\n",
        "    for i, mat in enumerate(list_mats):\n",
        "        if i % 100 == 0 and i > 0:\n",
        "            print(f\"Processed {i}/{len(list_mats)} files...\")\n",
        "\n",
        "        imname = mat[:-4] + '.jpg'\n",
        "        image_path = os.path.join(origimage_dir, imname)\n",
        "        mat_path = os.path.join(mat_dir, mat)\n",
        "\n",
        "        image_size, mask = make_label(image_path, mat_path)\n",
        "        if image_size == 0:\n",
        "            skipped += 1\n",
        "            continue\n",
        "\n",
        "        processed += 1\n",
        "        shutil.copy(image_path, image_dir)\n",
        "\n",
        "        # Save mask with unique color per class\n",
        "        mpl.rcParams['savefig.pad_inches'] = 0\n",
        "        figsize = (image_size[1] / 100, image_size[0] / 100)\n",
        "        fig = plt.figure(figsize=figsize)\n",
        "        ax = plt.axes([0, 0, 1, 1], frameon=False)\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "        plt.autoscale(tight=True)\n",
        "\n",
        "        max_label = np.max(mask)\n",
        "        custom_cmap = color_map(N=max_label + 1)\n",
        "        ax.imshow(mask, cmap=custom_cmap, vmin=0, vmax=max_label)\n",
        "\n",
        "        save_path = os.path.join(label_dir, imname.replace('.jpg', '.png'))\n",
        "        plt.savefig(save_path, bbox_inches='tight', pad_inches=0)\n",
        "        plt.close(fig)\n",
        "\n",
        "    print(\"\\n--- Processing Complete ---\")\n",
        "    print(f\"Total processed: {processed}\")\n",
        "    print(f\"Total skipped (no objects found): {skipped}\")\n",
        "    print(f\"Colored masks saved to: {label_dir}\")"
      ],
      "metadata": {
        "id": "jFJeuY18846e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "id": "wkIM4xi09Iuk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3129d42c-0163-4ae1-f3fe-9d885c1d7318"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Base Directory: /content/drive/MyDrive/Pascal_dataset/\n",
            "Found 10103 annotation files to process.\n",
            "Processed 100/10103 files...\n",
            "Processed 200/10103 files...\n",
            "Processed 300/10103 files...\n",
            "Processed 400/10103 files...\n",
            "Processed 500/10103 files...\n",
            "Processed 600/10103 files...\n",
            "Processed 700/10103 files...\n",
            "Processed 800/10103 files...\n",
            "Processed 900/10103 files...\n",
            "Processed 1000/10103 files...\n",
            "Processed 1100/10103 files...\n",
            "Processed 1200/10103 files...\n",
            "Processed 1300/10103 files...\n",
            "Processed 1400/10103 files...\n",
            "Processed 1500/10103 files...\n",
            "Processed 1600/10103 files...\n",
            "Processed 1700/10103 files...\n",
            "Processed 1800/10103 files...\n",
            "Processed 1900/10103 files...\n",
            "Processed 2000/10103 files...\n",
            "Processed 2100/10103 files...\n",
            "Processed 2200/10103 files...\n",
            "Processed 2300/10103 files...\n",
            "Processed 2400/10103 files...\n",
            "Processed 2500/10103 files...\n",
            "Processed 2600/10103 files...\n",
            "Processed 2700/10103 files...\n",
            "Processed 2800/10103 files...\n",
            "Processed 2900/10103 files...\n",
            "Processed 3000/10103 files...\n",
            "Processed 3100/10103 files...\n",
            "Processed 3200/10103 files...\n",
            "Processed 3300/10103 files...\n",
            "Processed 3400/10103 files...\n",
            "Processed 3500/10103 files...\n",
            "Processed 3600/10103 files...\n",
            "Processed 3700/10103 files...\n",
            "Processed 3800/10103 files...\n",
            "Processed 3900/10103 files...\n",
            "Processed 4000/10103 files...\n",
            "Processed 4100/10103 files...\n",
            "Processed 4200/10103 files...\n",
            "Processed 4300/10103 files...\n",
            "Processed 4400/10103 files...\n",
            "Processed 4500/10103 files...\n",
            "Processed 4600/10103 files...\n",
            "Processed 4700/10103 files...\n",
            "Processed 4800/10103 files...\n",
            "Processed 4900/10103 files...\n",
            "Processed 5000/10103 files...\n",
            "Processed 5100/10103 files...\n",
            "Processed 5200/10103 files...\n",
            "Processed 5300/10103 files...\n",
            "Processed 5400/10103 files...\n",
            "Processed 5500/10103 files...\n",
            "Processed 5600/10103 files...\n",
            "Processed 5700/10103 files...\n",
            "Processed 5800/10103 files...\n",
            "Processed 5900/10103 files...\n",
            "Processed 6000/10103 files...\n",
            "Processed 6100/10103 files...\n",
            "Processed 6200/10103 files...\n",
            "Processed 6300/10103 files...\n",
            "Processed 6400/10103 files...\n",
            "Processed 6500/10103 files...\n",
            "Processed 6600/10103 files...\n",
            "Processed 6700/10103 files...\n",
            "Processed 6800/10103 files...\n",
            "Processed 6900/10103 files...\n",
            "Processed 7000/10103 files...\n",
            "Processed 7100/10103 files...\n",
            "Processed 7200/10103 files...\n",
            "Processed 7300/10103 files...\n",
            "Processed 7400/10103 files...\n",
            "Processed 7500/10103 files...\n",
            "Processed 7600/10103 files...\n",
            "Processed 7700/10103 files...\n",
            "Processed 7800/10103 files...\n",
            "Processed 7900/10103 files...\n",
            "Processed 8000/10103 files...\n",
            "Processed 8100/10103 files...\n",
            "Processed 8200/10103 files...\n",
            "Processed 8300/10103 files...\n",
            "Processed 8400/10103 files...\n",
            "Processed 8500/10103 files...\n",
            "Processed 8600/10103 files...\n",
            "Processed 8700/10103 files...\n",
            "Processed 8800/10103 files...\n",
            "Processed 8900/10103 files...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eb-lDk37JLgF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}